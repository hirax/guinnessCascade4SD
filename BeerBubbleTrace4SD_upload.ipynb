{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture( 'input.mov' )\n",
    "isFirst = True  # （前回画像が無い）冒頭フレーム対応\n",
    "while( cap.isOpened() ):\n",
    "    ret, frame = cap.read()     # 動画からフレーム取得\n",
    "    if ret:\n",
    "        if isFirst: # i==0: #isFirst:\n",
    "            prvs = frame[ :, :, 2 ] # 直前画像として保存 （緑色を使用）\n",
    "            # 流れ速度を使った着色可視化用配列\n",
    "            rgb = np.zeros_like( frame ); rgb[...,0] = 0\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'MJPG') # 処理結果保存用の動画コーデック\n",
    "            # 処理結果を保存する動画ファイルを開く\n",
    "            out = cv2.VideoWriter( 'result.avi', fourcc, 30, prvs.shape[ ::-1 ] )            \n",
    "            # 速度場のXY座標群 (右辺座標はopenCV、左辺はmatplotlib)\n",
    "            X, Y = np.meshgrid( np.arange( 0, frame.shape[1] ), \n",
    "                                           np.arange( frame.shape[0], 0, -1 ) )\n",
    "        else:\n",
    "            next = frame[ :, :, 2 ]\n",
    "            flow = cv2.calcOpticalFlowFarneback(  # optical flow 算出 \n",
    "                prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            prvs = next  # 処理したフレームを「前回画像」に格納\n",
    "            rgb[..., 2] = cv2.normalize( flow[...,1], None, 0, 255, cv2.NORM_MINMAX )\n",
    "            rgb[..., 1] = 255 - rgb[..., 2]            \n",
    "            # 速度場 (右辺はopenCV座標、左辺はmatplotlib)\n",
    "            dx = flow[...,0]; dy = flow[...,1] \n",
    "            # matplotlibで流れ場を描画\n",
    "            fig = plt.figure( figsize = prvs.shape[::-1], dpi=1 )\n",
    "            fig.patch.set_facecolor('black') \n",
    "            ax = fig.gca();  ax.axis('off')\n",
    "            plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "            pitch = 15      # 流れ場を描く「間隔」\n",
    "            plt.quiver( X[::pitch, ::pitch],    Y[ ::pitch, ::pitch ], \n",
    "                           dx[::pitch, ::pitch], -dy[::pitch, ::pitch],\n",
    "                np.sqrt( dx[::pitch, ::pitch]**2 + dy[::pitch, ::pitch]**2 ),\n",
    "                units=\"xy\", scale=0.05, cmap=\"RdYlBu\",\n",
    "                linewidth=7 )\n",
    "            fig.canvas.draw() # matplotlib レンダリング結果を画像に格納\n",
    "            image = np.array( fig.canvas.renderer._renderer )\n",
    "            plt.close(fig)\n",
    "            # 動画として保存する\n",
    "            rgb = cv2.addWeighted( rgb, 0.5, image[...,0:3], 0.5, 1.0)\n",
    "            out.write( rgb )\n",
    "        isFirst = False\n",
    "    else:\n",
    "        cap.release(); out.release() # 入力動画・出力動画ともに閉じる\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
